You can **stay on `isnet-general-use`** and still get much better results for “white coat on white background” by adding **one simple trick + mask repair**. The core issue is that IS-Net (like other saliency-style removers) can treat low-contrast regions (white-on-white) as background; Cloudflare showed similar failures where IS-Net/U²-Net keep only the “salient” part (e.g., a logo) and drop the rest of the object. ([The Cloudflare Blog][1])

Below is a CPU-friendly approach that keeps **IS-Net** but makes the coat “visible” to it.

---

## Approach that works well with `isnet-general-use` (no BiRefNet)

### 1) Run IS-Net twice and **union the masks**

* Pass A: normal image
* Pass B: **background-tinted** image (only the background is recolored to mid-gray)
* Then: `mask = max(maskA, maskB)` (union)

Why this helps: if the background is near-white, tinting it creates contrast so IS-Net is less likely to erase the white coat.

`rembg` supports `only_mask=True` and `post_process_mask=True`, and IS-Net is one of its listed models. ([GitHub][2])

### 2) Fill holes + mild dilation (coat “interior” recovery)

After union, do:

* **hole fill** (classic OpenCV technique) ([LearnOpenCV][3])
* small **morphological close/dilate** to reconnect thin coat edges

### 3) Keep alpha as PNG RGBA (avoid “black background” surprises)

Always save to PNG and keep alpha; don’t convert to JPG/RGB.

---

## Single-file Python implementation (IS-Net only)

```python
# isnet_white_on_white_fix.py
import io
import numpy as np
import cv2
from PIL import Image
from functools import lru_cache
from rembg import new_session, remove

@lru_cache(maxsize=1)
def get_isnet_session():
    # Use CPU provider
    return new_session("isnet-general-use", providers=["CPUExecutionProvider"])

def pil_to_bgr(img: Image.Image) -> np.ndarray:
    rgba = np.array(img.convert("RGBA"))
    bgr = cv2.cvtColor(rgba, cv2.COLOR_RGBA2BGR)
    return bgr

def bgr_to_pil(bgr: np.ndarray) -> Image.Image:
    rgba = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGBA)
    return Image.fromarray(rgba, "RGBA")

def isnet_mask(img_pil: Image.Image) -> np.ndarray:
    # rembg supports only_mask + post_process_mask :contentReference[oaicite:3]{index=3}
    m = remove(
        img_pil,
        session=get_isnet_session(),
        only_mask=True,
        post_process_mask=True,
    )
    return np.array(m.convert("L"), dtype=np.uint8)

def floodfill_background_mask(bgr: np.ndarray, tol: int = 12) -> np.ndarray:
    """
    Background mask using flood-fill from 4 corners with tolerance.
    Works best when subject does NOT touch borders.
    """
    h, w = bgr.shape[:2]
    bg = np.zeros((h, w), dtype=np.uint8)

    # OpenCV floodFill uses a mask that is 2 pixels larger
    def fill_from(seedx, seedy):
        mask = np.zeros((h + 2, w + 2), dtype=np.uint8)
        flags = 4 | cv2.FLOODFILL_MASK_ONLY | (255 << 8)
        lo = (tol, tol, tol)
        up = (tol, tol, tol)
        cv2.floodFill(bgr.copy(), mask, (seedx, seedy), (0, 0, 0), lo, up, flags)
        return mask[1:-1, 1:-1]

    corners = [(0, 0), (w - 1, 0), (0, h - 1), (w - 1, h - 1)]
    for x, y in corners:
        bg = cv2.bitwise_or(bg, fill_from(x, y))

    return (bg > 0).astype(np.uint8) * 255

def tint_background(bgr: np.ndarray, bgmask: np.ndarray, tint_bgr=(160, 160, 160)) -> np.ndarray:
    out = bgr.copy()
    out[bgmask > 0] = np.array(tint_bgr, dtype=np.uint8)
    return out

def fill_holes(binary01: np.ndarray) -> np.ndarray:
    """
    Fill holes using flood fill (LearnOpenCV style). :contentReference[oaicite:4]{index=4}
    binary01: 0/1 image
    """
    img = (binary01 * 255).astype(np.uint8)
    h, w = img.shape[:2]
    ff = img.copy()
    mask = np.zeros((h + 2, w + 2), np.uint8)
    cv2.floodFill(ff, mask, (0, 0), 255)  # fill background from corner
    ff_inv = cv2.bitwise_not(ff)
    filled = cv2.bitwise_or(img, ff_inv)
    return (filled > 0).astype(np.uint8)

def improve_mask(mask_u8: np.ndarray) -> np.ndarray:
    """
    Repair mask so white coat parts are less likely to be cut out.
    """
    # Make a permissive binary foreground (low threshold keeps weak coat pixels)
    fg = (mask_u8 >= 20).astype(np.uint8)

    # Close small gaps and reconnect edges
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    fg = cv2.morphologyEx(fg, cv2.MORPH_CLOSE, k, iterations=1)
    fg = fill_holes(fg)

    # Mild dilation to recover thin missing regions
    fg = cv2.dilate(fg, k, iterations=1)

    # Combine: keep original soft alpha where it exists, but force-fill recovered regions
    alpha = np.maximum(mask_u8, fg.astype(np.uint8) * 255)
    return alpha

def remove_bg_isnet_cpu(image_bytes: bytes, max_side: int = 1024) -> bytes:
    img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")

    # Optional safety: cap resolution for CPU/RAM
    w, h = img.size
    m = max(w, h)
    if m > max_side:
        scale = max_side / float(m)
        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)

    bgr = pil_to_bgr(img)
    bgmask = floodfill_background_mask(bgr, tol=12)
    tinted = tint_background(bgr, bgmask, tint_bgr=(160, 160, 160))

    # Pass A/B masks and union them
    mask_a = isnet_mask(img)
    mask_b = isnet_mask(bgr_to_pil(tinted))
    mask = np.maximum(mask_a, mask_b)

    # Repair
    alpha = improve_mask(mask)

    rgba = np.array(img, dtype=np.uint8)
    rgba[:, :, 3] = alpha

    out = Image.fromarray(rgba, "RGBA")
    buf = io.BytesIO()
    out.save(buf, format="PNG")
    return buf.getvalue()
```

---

## Notes (so you don’t get stuck again)

* This uses **only `isnet-general-use`** (no BiRefNet), but still uses `rembg` features like **`only_mask`** and **`post_process_mask`**. ([GitHub][4])
* The “tint background” step assumes the subject **doesn’t touch image borders**. If the coat touches the border, flood-fill can leak into it (then tinting would also tint the coat). If that happens, I’ll adjust the background detection to be safer (edge strip sampling + stricter tolerance).
* If you want, paste 10–20 lines of your FastAPI endpoint (how you read/save the image). I can show exactly where to plug `remove_bg_isnet_cpu()` and make sure you’re not accidentally flattening alpha.

[1]: https://blog.cloudflare.com/background-removal/?utm_source=chatgpt.com "Evaluating image segmentation models for background ..."
[2]: https://github.com/danielgatis/rembg?utm_source=chatgpt.com "Rembg is a tool to remove images background"
[3]: https://learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/?utm_source=chatgpt.com "Filling holes in an image using OpenCV ( Python / C++ )"
[4]: https://github.com/danielgatis/rembg/blob/main/USAGE.md?utm_source=chatgpt.com "rembg/USAGE.md at main"